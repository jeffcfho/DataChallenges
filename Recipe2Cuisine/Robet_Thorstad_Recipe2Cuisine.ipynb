{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KTCaQpx8IH9s"
   },
   "source": [
    "# Robert Thorstad - Recipe2Cuisine Data Challenge\n",
    "\n",
    "Hi! The following code accompanies my Data Challenge submission for Recipe2Cuisine.\n",
    "\n",
    "There are 4 sections below:\n",
    "* Clean and preprocess data\n",
    "* Exploratory data analysis\n",
    "* Train model\n",
    "* Produce figures\n",
    "\n",
    "The code does assume a basic project directory structure, with the recipes in data/recipes.json and this Python code in scripts/. It also assumes the directories models/ and results/ exist. Thus while the code will not run in a Jupyter environment without these directories, it should be explanatory!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lKAz-IBnFfF7"
   },
   "source": [
    "# Clean and Preprocess Data\n",
    "\n",
    "*   **Remove** poorly formatted recipes, defined as recipes with <3 ingredients or no label (N = 225)\n",
    "\n",
    "*   **Represent** recipes as lowercase bag-of-unigrams. Note: I tried stemming recipes (e.g. \"onions\" -> \"onion\") but this performs poorly on foreign-language words, which are frequent in the recipes. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UQzV4EZGFytw"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pickle\n",
    "\n",
    "\n",
    "def remove_bad_recipies():\n",
    "    \"\"\"\n",
    "    remove any 'bad' recipes from the dataset, defined as recipes\n",
    "    with < 3 ingredients or no label.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load dataset.\n",
    "    data_p = os.path.join(\"..\", \"data\", \"recipies.json\")\n",
    "    j = json.loads(open(data_p, \"r\").read())\n",
    "\n",
    "    # Create output file.\n",
    "    of_p = os.path.join(\"..\", \"data\", \"2_recipes_bad_exs_removed.jsonl\")\n",
    "    of = open(of_p, \"w\", newline=\"\")\n",
    "\n",
    "    n_bad = 0\n",
    "    for recipe_j in j:\n",
    "\n",
    "        valid_label = \"cuisine\" in recipe_j.keys()\n",
    "        enough_ingredients = len(recipe_j[\"ingredients\"]) >= 3\n",
    "\n",
    "        if valid_label and enough_ingredients:\n",
    "            out = json.dumps(recipe_j) + \"\\n\"\n",
    "            of.write(out)\n",
    "\n",
    "        else:\n",
    "            n_bad += 1\n",
    "\n",
    "\n",
    "    of.flush()\n",
    "    of.close()\n",
    "    print(\"done, removed {} recipes\".format(n_bad))\n",
    "\n",
    "def preprocess_recipes():\n",
    "    \"\"\"\n",
    "    represent each recipe as a list of stemmed unigrams.\n",
    "    output recipes as feature matrix.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load recipes.\n",
    "    print(\"load recipes\")\n",
    "    in_p = os.path.join(\"..\", \"data\", \"2_recipes_bad_exs_removed.jsonl\")\n",
    "    js = [json.loads(row) for row in open(in_p, \"r\").readlines()]\n",
    "\n",
    "    # Represent recipes using two arrays: stemmed unigrams and targets.\n",
    "    print(\"represent recipes -> stemmed unigrams\")\n",
    "    unigrams = [] # list of strings, each idx is a recipe.\n",
    "    cuisines = [] # each idx is a recipe, value is cuisine as string.\n",
    "\n",
    "    for idx, j in enumerate(js):\n",
    "\n",
    "        # counter.\n",
    "        if idx % 5000 == 0:\n",
    "            print(idx)\n",
    "\n",
    "        # get data.\n",
    "        cuisine = j[\"cuisine\"]\n",
    "        ingredients = j[\"ingredients\"]\n",
    "\n",
    "        # tokenize and lowercase ingredients.\n",
    "        stemmed_ = [] # stemmed unigrams for this cuisine.\n",
    "        joined = \" \".join(ingredients)\n",
    "        lower = joined.lower()\n",
    "        toks = lower.split()\n",
    "\n",
    "        # add ingredients, target to data structure.\n",
    "        joined_unigrams = \" \".join(toks)\n",
    "        unigrams.append(joined_unigrams)\n",
    "        cuisines.append(cuisine)        \n",
    "\n",
    "    # Create X feature matrix.\n",
    "    print(\"vectorize ingredients\")\n",
    "    vectorizer = CountVectorizer()\n",
    "    X = vectorizer.fit_transform(unigrams)\n",
    "    print(X.shape)\n",
    "\n",
    "    # Integer encode recipes. \n",
    "    target_encoder = LabelEncoder()\n",
    "    y = target_encoder.fit_transform(cuisines)\n",
    "    print(y[:10])\n",
    "\n",
    "    # Save data, vectorizer.\n",
    "    pickle.dump(obj=X, file=open(\"../data/X.pkl\", \"wb\"))\n",
    "    pickle.dump(obj=y, file=open(\"../data/y.pkl\", \"wb\"))\n",
    "    pickle.dump(obj=vectorizer, file=open(\"../models/vectorizer.pkl\", \"wb\"))\n",
    "    pickle.dump(obj=target_encoder, file=open(\"../models/label_encoder.pkl\", \"wb\"))\n",
    "    print(\"done, saved data/X.pkl, data/y.pkl, models/vectorizer.pkl\", \"models/label_encoder.pkl\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    #remove_bad_recipies()\n",
    "    preprocess_recipes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xw94gLtOF6qv"
   },
   "source": [
    "# Exploratory Data Analysis\n",
    "\n",
    "\n",
    "\n",
    "*   Plot **distribution of data** by class. (Note: moderately imbalanced) \n",
    "\n",
    "*   Check dataset **shapes** (~39.5k rows of data, 20 classes)\n",
    "\n",
    "*   **Visual inspection** revealed data is relatively clean with few formatting errors, typos, etc.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ks-dYKuIGUa3"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def do_eda():\n",
    "    \"\"\" \n",
    "    Do simple EDA.\n",
    "    Size of dataset?\n",
    "    Class distribution?\n",
    "    Total number of classes?\n",
    "    \"\"\"\n",
    "\n",
    "    # Load X, y data.\n",
    "    print(\"load data\")\n",
    "    X = pickle.load(open(\"../data/X.pkl\", \"rb\"))\n",
    "    y = pickle.load(open(\"../data/y.pkl\", \"rb\"))\n",
    "\n",
    "    # Size of dataset.\n",
    "    print(\"X shape : {}\".format(X.shape))\n",
    "\n",
    "    # Class distribution.\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.hist(y)\n",
    "    plt.xticks(range(20))\n",
    "    plt.title(\"class distribution\")\n",
    "    plt.show()\n",
    "\n",
    "    # Total number of classes.\n",
    "    n_classes = len(set(y))\n",
    "    print(\"# of classes {}\".format(n_classes))    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    do_eda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xh8BadnhGWYR"
   },
   "source": [
    "# Train Model\n",
    "\n",
    "* Train a **ridge regression** model to classify the cuisine of a recipe, based on cuisine. In evaluating this model I also tried a random forest. \n",
    "\n",
    "* Model the **\"essence\" of a cuisine** using feature importances (top-5 regression weights / class).\n",
    "\n",
    "* Save **model statistics** including F1 by class, confusion matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2eNlE4_WGwKK"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def train_model():\n",
    "\n",
    "    # Load data and relevant objects for ml.\n",
    "    X = pickle.load(open(\"../data/X.pkl\", \"rb\"))\n",
    "    y = pickle.load(open(\"../data/y.pkl\", \"rb\"))\n",
    "    label_encoder = pickle.load(open(\"../models/label_encoder.pkl\", \"rb\")) \n",
    "\n",
    "    # List idx -> label mapping.\n",
    "    ylabels = []\n",
    "    for idx in range(20):\n",
    "        lbl = label_encoder.inverse_transform([idx])\n",
    "        print(idx, lbl)\n",
    "        ylabels.append(lbl[0])\n",
    "\n",
    "    # Train/test split.\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "    # Train and evaluate models.\n",
    "    models = [RidgeClassifier()]\n",
    "    labels = [\"Ridge\"]\n",
    "\n",
    "    for clf, lbl in zip(models, labels):\n",
    "\n",
    "        # train\n",
    "        print(\"train \" + lbl)\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        # score.\n",
    "        report = classification_report(y_test, clf.predict(X_test))\n",
    "        print(report)\n",
    "\n",
    "        # optionally, save.\n",
    "        if lbl == \"Ridge\":\n",
    "            model_of_p = \"../models/ridge.pkl\"\n",
    "            pickle.dump(clf, open(model_of_p, \"wb\"))\n",
    "            print(\"wrote {}\".format(model_of_p))\n",
    "\n",
    "        # confusion matrix.\n",
    "        cm = confusion_matrix(y_test, clf.predict(X_test))\n",
    "        sns.heatmap(cm, xticklabels=ylabels, yticklabels=ylabels)\n",
    "        sns.set(font_scale = 2)\n",
    "        hm_p = \"../results/{}_confusion_matrix.png\".format(lbl)\n",
    "        print(\"write {}\".format(hm_p))\n",
    "        plt.savefig(hm_p)\n",
    "\n",
    "def explain_cuisines():\n",
    "    \"\"\" list most important features for each cuisine \"\"\"\n",
    "\n",
    "    # Load model, vectorizer, cuisine labels.\n",
    "    clf = pickle.load(open(\"../models/ridge.pkl\", \"rb\"))\n",
    "    label_encoder = pickle.load(open(\"../models/label_encoder.pkl\", \"rb\"))\n",
    "    vectorizer = pickle.load(open(\"../models/vectorizer.pkl\", \"rb\"))\n",
    "    idx_to_term = vectorizer.get_feature_names()\n",
    "\n",
    "    # Get feature importances.\n",
    "    coef_ = clf.coef_ # shape (n_classes, n_features).\n",
    "\n",
    "    # For each cuisine, list 5 most important features.\n",
    "    # Pause for user input between cuisines.\n",
    "    for cuisine_idx in range(coef_.shape[0]):\n",
    "\n",
    "        # Get indices of largest weights.\n",
    "        weights = coef_[cuisine_idx]\n",
    "        largest_weight_indices = np.argsort(weights)[::-1][:5]\n",
    "\n",
    "        # Get feature names for largest weights, and cusine name.\n",
    "        cuisine_name = label_encoder.inverse_transform([cuisine_idx])\n",
    "        important_feature_strs = [idx_to_term[idx] for idx in largest_weight_indices]\n",
    "        print(cuisine_name, important_feature_strs)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_model()\n",
    "    explain_cuisines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M8qCgCBCGx3V"
   },
   "source": [
    "# Create Figures\n",
    "\n",
    "* Plot **model performance** for ridge regression, random forest. \n",
    "\n",
    "* Plot **performance by cuisine**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2h1ON0nZG6qk"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_model_performance():\n",
    "\n",
    "    # initialize plot.\n",
    "    plt.close(\"all\")\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    sns.set(font_scale = 2)\n",
    "    sns.set_palette(\"deep\")\n",
    "\n",
    "    # plot\n",
    "    X = range(2)\n",
    "    y = [.75, .76]\n",
    "    plt.bar(0, y[0], width=.5)\n",
    "    plt.bar(1, y[1], width=.5)\n",
    "\n",
    "    # title, labels.\n",
    "    plt.ylabel(\"F1\")\n",
    "    plt.xticks([])\n",
    "    plt.yticks([0, .2, .4, .6, .8])\n",
    "\n",
    "    # save and show.\n",
    "    fig_p = \"../results/model_performance.png\"\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(fig_p)\n",
    "    plt.show()\n",
    "\n",
    "def plot_f1_by_class():\n",
    "\n",
    "    f1s = [.57, .44, .72, .78, .49, .59, .70, .85, .42, .81, .71, .75, .73, .88, .71,\n",
    "                .53, .73, .46, .74, .49]\n",
    "    lbls = [\n",
    "        \"Brazilian\",\n",
    "        \"British\",\n",
    "        \"Cajun/Creole\",\n",
    "        \"Chinese\",\n",
    "        \"Filipino\",\n",
    "        \"French\",\n",
    "        \"Greek\",\n",
    "        \"Indian\",\n",
    "        \"Irish\",\n",
    "        \"Italian\",\n",
    "        \"Jamaican\",\n",
    "        \"Japanese\",\n",
    "        \"Korean\",\n",
    "        \"Mexican\",\n",
    "        \"Moroccan\",\n",
    "        \"Russian\",\n",
    "        \"Southern US\",\n",
    "        \"Spanish\",\n",
    "        \"Thai\",\n",
    "        \"Vietnamese\"\n",
    "    ]\n",
    "\n",
    "    # initialize plot.\n",
    "    plt.close(\"all\")\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.set(font_scale = 2)\n",
    "    sns.set_palette(\"deep\")\n",
    "\n",
    "    # plot\n",
    "    X = range(20)\n",
    "    for xi, yi in zip(X, f1s):\n",
    "        plt.bar(xi, yi, width=0.8)\n",
    "\n",
    "    # title, labels.\n",
    "    plt.ylabel(\"F1\")\n",
    "    plt.xlabel(\"Cuisine\")\n",
    "    plt.xticks([])\n",
    "\n",
    "    # save and show.\n",
    "    fig_p = \"../results/performance_by_class.png\"\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(fig_p)\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    plot_model_performance()\n",
    "    plot_f1_by_class()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Robet_Thorstad_Recipe2Cuisine.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
